{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "automated number plate recognization using vgg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class vgg16(nn.Module):\n",
    "    def __init__(self,features,num_classes=1000):\n",
    "        super(vgg,self).__init__()\n",
    "        self.features=nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=3,padding=1) #layer1, inputs single channel,224*224\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            nn.Conv2d(64,128,kernel_size=3,padding=1) #layer2 inputs 64 channel,112*112\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(128,128,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            nn.Conv2d(128,256,kernel_size=3,padding=1) #layer3 inputs 128 channel,56*56\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            nn.Conv2d(256,512,kernel_size=3,padding=1) #layer4 inputs 256 channel,28*28\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1) #layer5 inputs 512 channel,14*14\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),            \n",
    "        )\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def forward(self.x):\n",
    "        x=self.features(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.classifier(x)\n",
    "        return x\n",
    "    )\n",
    "    \n",
    "    def __initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NPSET(data.Dataset):\n",
    "    picroot='np'\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img=self.dataset[index]\n",
    "        img=Image.fromarray(img.numpy(), mode='L')\n",
    "        if self.transform is not None:\n",
    "            img=self.transform(img)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __init__(self,root,transform=None):\n",
    "        self.picroot=root\n",
    "        self.transform=transform\n",
    "        \n",
    "        if not os.path.exists(self.picroot):\n",
    "            raise RuntimeError('{} doesnot exists'.format(self.picroot))\n",
    "        for root,dnames,filenames in os.walk(self.picroot):\n",
    "            imgs=np.ndarray(shape=(len(filenames),224,224),dtype=np.float)\n",
    "            i=0\n",
    "            for filename in filenames:\n",
    "                picfilename=os.path.join(self.picroot,filename)  #file name:\n",
    "                im=cv2.imread(picfilename,cv2.IMREAD_GRAYSCALE)\n",
    "                im=cv2.resize(im,(224,224))\n",
    "                #(thresh, im) = cv2.threshold(im, 32, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)   \n",
    "                #im=cv2.erode(im,self.kernel)\n",
    "                #im=cv2.dilate(im,self.kernel)\n",
    "                #im=cv2.GaussianBlur(im,(5,5),0.1)\n",
    "                #(thresh, im) = cv2.threshold(im, 32, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)   \n",
    "                imgs[i]=im/255\n",
    "                i=i+1\n",
    "            self.dataset=torch.FloatTensor(imgs)\n",
    "            self.len=len(filenames)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=vgg16()  #number class =?\n",
    "model.features=torch.nn.DataParallel(model.features)\n",
    "model.cuda()\n",
    "cudnn.benchmark=True\n",
    "batch_size=10\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.449,), (0.226,)),\n",
    "                             ])\n",
    "npset = NPSET(root='np', transform=transform)\n",
    "nploader = torch.utils.data.DataLoader(npset, batch_size=batch, shuffle=False, num_workers=1)  #train\n",
    "npvalset=NPSET(root='npval', transform=transform)\n",
    "npvalloader=torch.utils.data.DataLoader(npvalset, batch_size=batch, shuffle=False, num_workers=1) #validate\n",
    "criterion=nn.CrossEntropyLoss().cuda()\n",
    "optimizer=torch.optim.SGD(model.parameters,0.1,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()        \n",
    "for epoch in range(0,90):\n",
    "    #Sets the learning rate to the initial LR decayed by 10 every 30 epochs\n",
    "    lr=0.1*(0.1**(epoch//30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr']=lr\n",
    "    #train\n",
    "    model.train()\n",
    "    for i,data in enumerate(nploader):\n",
    "        inputs,target = data\n",
    "        target=target.cuda()\n",
    "        input_var=torch.autograd.Variable(inputs)\n",
    "        target_var=torch.autograd.Variable(target)\n",
    "        output=model(input_var)\n",
    "        loss=criterion(output,target_var)\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #\n",
    "        if i% 10 == 0:\n",
    "            print('Eoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})').format(i,len(nploader),loss=losses,top1=top1,top5=top5)\n",
    "        \n",
    "    #validate\n",
    "    model.eval()\n",
    "    for i, data in enumerate(npvalloader):\n",
    "        (inputs, target)=data\n",
    "        target = target.cuda()\n",
    "        input_var = torch.autograd.Variable(inputs, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data[0], inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "        top5.update(prec5[0], inputs.size(0))\n",
    "        #\n",
    "        if i % 10 == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   i, len(npvalloader), loss=losses,\n",
    "                   top1=top1, top5=top5))\n",
    "        prec1=top1.avg\n",
    "        # remember best prec@1 and save checkpoint\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "    if is_best:\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch:vgg16',\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
