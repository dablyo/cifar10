{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                             ])\n",
    "trainset = mnist.MNIST(root='MNIST', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=2)\n",
    "\n",
    "testset = mnist.MNIST(root='MNIST', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "classes = ('0','1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 9\n",
      " 8\n",
      " 0\n",
      " 4\n",
      "[torch.LongTensor of size 4]\n",
      "\n",
      "    9     8     0     4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB2CAYAAADY3GjsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0ImIPPH/Qn0fVpcPqUoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdd286ccf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# functions to show an image\n",
    "%matplotlib inline\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "\n",
    "# show some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print labels\n",
    "print(' '.join('%5s'%classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        #self.pool  = nn.MaxPool2d(2,2)\n",
    "        #self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #self.fc1   = nn.Linear(16*4*4, 120)\n",
    "        #self.fc2   = nn.Linear(120, 84)\n",
    "        #self.fc3   = nn.Linear(84, 10)\n",
    "        #self.conv2drop=nn.Dropout2d()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = F.relu(self.pool(self.conv1(x)))\n",
    "        #x = F.relu(self.pool(self.conv2drop(self.conv2(x))))\n",
    "        #x = x.view(-1, 16*4*4)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        #x = self.fc3(x)\n",
    "        #return F.log_softmax(x)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)        \n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Net()\n",
    "#net.cuda()  #cuda\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.180\n",
      "[1,  4000] loss: 0.188\n",
      "[1,  6000] loss: 0.182\n",
      "[1,  8000] loss: 0.194\n",
      "[1, 10000] loss: 0.172\n",
      "[1, 12000] loss: 0.195\n",
      "[1, 14000] loss: 0.189\n",
      "[2,  2000] loss: 0.180\n",
      "[2,  4000] loss: 0.165\n",
      "[2,  6000] loss: 0.175\n",
      "[2,  8000] loss: 0.185\n",
      "[2, 10000] loss: 0.177\n",
      "[2, 12000] loss: 0.185\n",
      "[2, 14000] loss: 0.181\n",
      "[3,  2000] loss: 0.168\n",
      "[3,  4000] loss: 0.164\n",
      "[3,  6000] loss: 0.184\n",
      "[3,  8000] loss: 0.178\n",
      "[3, 10000] loss: 0.169\n",
      "[3, 12000] loss: 0.164\n",
      "[3, 14000] loss: 0.181\n",
      "[4,  2000] loss: 0.168\n",
      "[4,  4000] loss: 0.164\n",
      "[4,  6000] loss: 0.171\n",
      "[4,  8000] loss: 0.178\n",
      "[4, 10000] loss: 0.173\n",
      "[4, 12000] loss: 0.163\n",
      "[4, 14000] loss: 0.169\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        #inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda()) #cuda\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        #loss = criterion(outputs, labels)\n",
    "        loss =  F.nll_loss(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999: # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GroundTruth: ', '    7     2     1     0')\n",
      "\n",
      " 7\n",
      " 2\n",
      " 1\n",
      " 0\n",
      "[torch.LongTensor of size 4x1]\n",
      " (\n",
      "-5.4122e-11\n",
      "-2.9622e-05\n",
      "-1.5138e-02\n",
      "-9.0293e-08\n",
      "[torch.FloatTensor of size 4x1]\n",
      ", \n",
      " 7\n",
      " 2\n",
      " 1\n",
      " 0\n",
      "[torch.LongTensor of size 4x1]\n",
      ")\n",
      "('Predicted: ', '    7     2     1     0')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB2CAYAAADY3GjsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdd286cc890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s'%classes[labels[j]] for j in range(4)))\n",
    "\n",
    "outputs = net(Variable(images))\n",
    "#outputs = net(Variable(images).cuda())  #cuda\n",
    "\n",
    "# the outputs are energies for the 10 classes.\n",
    "# Higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class\n",
    "\n",
    "# So, let's get the index of the highest energy\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "p = torch.max(outputs.data, 1)\n",
    "print predicted,p\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s'% classes[predicted[j][0]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data    \n",
    "    #images, labels = Variable(images.cuda()), Variable(labels.cuda()) #cuda\n",
    "    #images, labels = Variable(images), Variable(labels) \n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    #correct += (predicted == labels.data).sum()  #cuda\n",
    "    \n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of     0 : 97 %\n",
      "Accuracy of     1 : 98 %\n",
      "Accuracy of     2 : 95 %\n",
      "Accuracy of     3 : 97 %\n",
      "Accuracy of     4 : 96 %\n",
      "Accuracy of     5 : 94 %\n",
      "Accuracy of     6 : 94 %\n",
      "Accuracy of     7 : 94 %\n",
      "Accuracy of     8 : 93 %\n",
      "Accuracy of     9 : 92 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))classes = ('0','1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    #images, labels = Variable(images.cuda()), Variable(labels.cuda()) #cuda \n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    #c = (predicted == labels.data).squeeze()  #cuda\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        #label = labels[i].data #cuda\n",
    "        #label = label.cpu().numpy()[0]  #cuda\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'/home/wang/git/cifar10/mnist.weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
