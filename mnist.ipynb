{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                             ])\n",
    "trainset = mnist.MNIST(root='MNIST', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=2)\n",
    "\n",
    "testset = mnist.MNIST(root='MNIST', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "classes = ('0','1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2\n",
      " 6\n",
      " 0\n",
      " 1\n",
      "[torch.LongTensor of size 4]\n",
      "\n",
      "    2     6     0     1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB2CAYAAADY3GjsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIA98AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa69aee9ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# functions to show an image\n",
    "%matplotlib inline\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "\n",
    "# show some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print labels\n",
    "print(' '.join('%5s'%classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        #self.pool  = nn.MaxPool2d(2,2)\n",
    "        #self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #self.fc1   = nn.Linear(16*4*4, 120)\n",
    "        #self.fc2   = nn.Linear(120, 84)\n",
    "        #self.fc3   = nn.Linear(84, 10)\n",
    "        #self.conv2drop=nn.Dropout2d()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)inputarray[i][0]=np.asarray(list(timg.getdata())).reshape((28,28))\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = F.relu(self.pool(self.conv1(x)))\n",
    "        #x = F.relu(self.pool(self.conv2drop(self.conv2(x))))\n",
    "        #x = x.view(-1, 16*4*4)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        #x = self.fc3(x)\n",
    "        #return F.log_softmax(x)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)        \n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Net()\n",
    "#net.cuda()  #cuda\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.543246\n",
      "Train Epoch: 0 [4000/60000 (13%)]\tLoss: 0.121964\n",
      "Train Epoch: 0 [8000/60000 (27%)]\tLoss: 0.000517\n",
      "Train Epoch: 0 [12000/60000 (40%)]\tLoss: 0.241892\n",
      "Train Epoch: 0 [16000/60000 (53%)]\tLoss: 0.084773\n",
      "Train Epoch: 0 [20000/60000 (67%)]\tLoss: 0.002913\n",
      "Train Epoch: 0 [24000/60000 (80%)]\tLoss: 0.361334\n",
      "Train Epoch: 0 [28000/60000 (93%)]\tLoss: 0.185321\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.032069\n",
      "Train Epoch: 1 [4000/60000 (13%)]\tLoss: 0.008074\n",
      "Train Epoch: 1 [8000/60000 (27%)]\tLoss: 0.000908\n",
      "Train Epoch: 1 [12000/60000 (40%)]\tLoss: 0.002586\n",
      "Train Epoch: 1 [16000/60000 (53%)]\tLoss: 0.000037\n",
      "Train Epoch: 1 [20000/60000 (67%)]\tLoss: 0.288805\n",
      "Train Epoch: 1 [24000/60000 (80%)]\tLoss: 0.302003\n",
      "Train Epoch: 1 [28000/60000 (93%)]\tLoss: 0.023371\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        #inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda()) #cuda\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        #loss = criterion(outputs, labels)\n",
    "        loss =  F.nll_loss(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        # if i % 2000 == 1999: # print every 2000 mini-batches\n",
    "        if i % 2000 == 0: # print every 2000 mini-batches    \n",
    "            #print('[%d, %5d] loss: %.3f' % (epoch+1, i, running_loss / 2000))\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(data), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader), loss.data[0]))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GroundTruth: ', '    7     2     1     0')\n",
      "\n",
      " 7\n",
      " 2\n",
      " 1\n",
      " 0\n",
      "[torch.LongTensor of size 4x1]\n",
      " (\n",
      "-5.4122e-11\n",
      "-2.9622e-05\n",
      "-1.5138e-02\n",
      "-9.0293e-08\n",
      "[torch.FloatTensor of size 4x1]\n",
      ", \n",
      " 7\n",
      " 2\n",
      " 1\n",
      " 0\n",
      "[torch.LongTensor of size 4x1]\n",
      ")\n",
      "('Predicted: ', '    7     2     1     0')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB2CAYAAADY3GjsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAENBJREFUeJzt3XuMVEW+B/Dvz+EhLImCII7IOCMZuUF8IC1yWTFEWC8g\niPhCIoYYw6hBnF0XvCBqXI26EkPu1SAEV+6ibvABKCOiyB1BMAGWGYFFHsNr5eWMA64KKMrD3/7R\n59TUMN30+/R09feTEH5dfbrPr3p6as6pU6dKVBVERJT7zsp2AkRElB5s0ImIHMEGnYjIEWzQiYgc\nwQadiMgRbNCJiBzBBp2IyBEpNegiMlhEakRkp4hMTldSRESUOEn2xiIRKQCwHcDvAOwHsA7AaFXd\nkr70iIgoXi1SeG0fADtVdTcAiMhbAEYAiNqgd+zYUYuLi1PYJRFR/qmurj6kqp1ibZdKg94FwD7r\n8X4A156+kYiUASgDgKKiIlRVVaWwSyKi/CMie+LZLuMXRVV1tqqGVDXUqVPMPzBERJSkVBr0AwC6\nWo8v8sqIiCgLUmnQ1wEoFZESEWkF4C4AFelJi4iIEpV0H7qqnhSRhwAsBVAAYI6qbk5bZkRElJBU\nLopCVZcAWJJqEiKS6lvkpUhDTvlZJifa8F1+nsnh55kdvFOUiMgRbNCJiBzBBp2IyBFs0ImIHMEG\nnYjIEWzQiYgcwQadiMgRKY1DJ5o4caKJ27RpY+IrrrjCxLfffnuT182cOdPEq1evNvEbb7yR7hSJ\n8gaP0ImIHMEGnYjIEexyoYS9/fbbJo7UnXK6X3/9tUnZ/fffb+JBgwaZeMWKFSbet8+ebp/iVVpa\nauKamhoAQHl5uSl7+eWXA8+pOWnbtq2JX3zxRRPb38nq6moAjb/fe/fuDSC71PAInYjIEWzQiYgc\nwS4Xipvf1RJPN8u2bdtMvHTpUgDAJZdcYsqGDx9u4m7dupn4nnvuMfFzzz2XfLJ57Oqrrzax3911\n4ADXnvFdeOGFJh43bpyJ7a7B3r17A2j8PZ0xY0YA2aWGR+hERI7gETqdkX+kAgAjR45s8vzmzQ1r\nmthHM4cOHTLxjz/+CABo2bKlKVu7dq2Jr7zyShN36NAhxYzpqquuMrH/2S9cuDBb6TQbHTt2BADM\nnTs3y5lkDo/QiYgcwQadiMgRTnS52Bfp7IscX3/9tYl//vlnAMCbb75pyurq6ky8a9euTKaYs+wL\nSP7yYXY3y4033mhi+/OMZNKkSSbu0aNHxG0+/PDDpPLMdz179jTxhAkTTPz6669nI51m4+GHHzbx\nLbfcAgDo06dP3K+//vrrTXzWWQ3Hvxs2bDDxqlWrUkkxrWIeoYvIHBGpF5EvrbIOIrJMRHZ4/7fP\nbJpERBRLPF0ufwUw+LSyyQAqVbUUQKX3mIiIskiirc7daCORYgCLVbWn97gGwABVrRWRQgArVLV7\nrPcJhUJaVVUV6f0TTLux3bt3m7i4uDju1x05csTEdjdCOu3fv9/EL7zwgon9W4tTEelnl8lV1YuK\nigA0/ty+++67uF+/ceNGE9tdBDZ7GoDly5cnmmLScn2Vervb8Z133jHxgAEDAAArV64MNJ/m8nme\nOnXKxJGmoIjG716J9po9e/aY+M477zTxF198kWiK8apW1VCsjZK9KNpZVWu9uA5A52gbikiZiFSJ\nSNXBgweT3B0REcWS8igXDf8pjnqYr6qzVTWkqqFOnTqlujsiIooi2VEu34hIodXlUp/OpBJlj2yx\nb1LZsmWLif1RFb169TJl/ukoAPTt29fE9ix/Xbt2PeO+T548aWL7DKSwsLDJtvZsbenocglasrPN\n+aNbLr300ojP2zcZrVmzJql95LtHH33UxHZ3QKQuTtctWbLExPbIlER8++23AICjR4+asosvvtjE\nJSUlJl63bp2JCwoKktpfuiR7hF4BYKwXjwWwKD3pEBFRsuIZtjgPwGoA3UVkv4jcB+DPAH4nIjsA\nDPIeExFRFsXsclHV0VGeGpjmXJJWWVkZMbZ9/PHHTcrOPfdcE9sz1NmnULFuQjh27JiJt2/fbmJ/\ntkF7bhJ7NI7rhg0bZuKnn34aANCqVStTVl/f0Es3eXLDqFf786Qzs7sAQqGGARD29/Cnn34KNKds\nsW8A6t69YcCdPUol1iiXWbNmmfiTTz4BAHz//fembODAhiZv6tSpEd/jwQcfBNB4zdwg8dZ/IiJH\nOHHrf7Lsv76ffvppxG2iHfFHctttt5m4ffvwzbObNm0yZfPmzUs0xZxlHzHaR+Y+exm7oMdIu8K+\nqG/Ll+HB9hmK/X3yZ1WMxr5ovGDBAhM/9dRTJo50pmi/rqyszMT26L1p06YBAM4++2xTZi/5Zw+i\nyAQeoRMROYINOhGRI/K6yyUd7NOtV155xcT++Ff/giCQ2G3yuej99983sT0Lo8+e+S/aRSWK3+WX\nXx6x3D/td529YEqsbhYA+OyzzwAAo0aNMmX+ePN42PdhPP/88yaePn26idu2bQug8c9g0aKGUd2Z\nHhjBI3QiIkewQScicgS7XFL00EMPmdjufvG7V/zx6K664IILTNyvXz8Tt27d2sT++qLPPPOMKfPX\nuqTE2FNU3HvvvSZev369if0x1NR46gP/80qkmyUauxvl7rvvNvE111yT8nungkfoRESOYINOROQI\ndrkkwe5asG9bt40YMQJA5hbOaC4WLlxo4vPOOy/iNv46rvk09UGm2AuA2NNK2FNb/PLLL4Hm1BxE\nm1Xx2muvzcj+7IU67H1HysMe6TZmzJiM5GP2n9F3JyKiwLBBJyJyBLtcknDTTTeZ2L65wZ73ZfXq\n1YHmFKSbb77ZxPYslbYVK1aY+Mknn8x0SnnDXsDFXrdz/vz52Ugnqx544AETJ7JeaDrYvwP2ojl+\nHnY+QX7/eYROROQIHqHHyZ49bfDgwSY+fvy4ie2/xJmeVS0b/Itwjz32mCmzz1BsGzZsMDHHnKeu\nc+fwOuz9+/c3ZTU1NSZ+7733As8p24YPH57xfdhTCvjLWAKNfwcisWe8PHHiRPoTi4JH6EREjmCD\nTkTkCHa5xMleVd2+CGKP/3X5QigATJw4EUD025vt2RZ5ITS9/NvWzz//fFP20UcfZSudvPH444+b\nePz48TG3/+qrrwAAY8eONWX79u1Le17RxLNIdFcRWS4iW0Rks4iUe+UdRGSZiOzw/m+f+XSJiCia\neLpcTgL4o6r2ANAXwHgR6QFgMoBKVS0FUOk9JiKiLInZ5aKqtQBqvfiIiGwF0AXACAADvM3mAlgB\n4L8zkmUW+WPOn3jiCVN2+PBhE9u39brukUceOePz9ikpR7akl71+ps/1BVOyacmSJQCA7t27J/S6\nrVu3AgA+//zztOcUj4QuiopIMYBeANYC6Ow19gBQB6BzlNeUiUiViFTly+K1RETZEHeDLiLtACwA\n8HtVPWw/p+Fb1jTS61R1tqqGVDVkzxdORETpFdcoFxFpiXBj/jdV9afX+0ZEClW1VkQKAdRnKsmg\n2bPYvfTSSwCAgoICU+afjgHAmjVrgkusmbM/t0Rupvjhhx9MbN+Q1aJF+Ot5zjnnRHxd+/YN1+Fj\ndQedOnXKxPaIpWPHjsWdZzZFuolm8eLFWcik+Yg246FtyJAhTcpeffVVExcWFkZ8nf9+iU4pMGzY\nsIS2T7d4RrkIgNcAbFXV6dZTFQD8sTljASw6/bVERBSceI7QfwvgHgCbRMS/n/sxAH8G8I6I3Adg\nD4A7M5MiERHFI55RLp8DkChPD0xvOtljn7ItXbrUxCUlJQCAXbt2mTL7ZgNqsGnTpqRe9+6775q4\ntrbWxP78JaNGjUotsdPU1dWZ+Nlnn03re6fTddddZ2L/s6AGM2fONPG0adMibmN3S0XqPonVpRJP\nl8usWbNibhMU3vpPROQI3vrv6datm4l79+7d5Hn7olu+LqXmXwz2l9dLlzvuuCPube2LptGOnioq\nKgA0XvHdtmrVqgSyy56RI0ea2L8ov379elNmzzmfjxYsWGDiSZMmmTido+nsodb+GHMAGDdunInt\ns8ps4xE6EZEj2KATETkir7tcioqKTLxs2bKI2/inch988EEgOTVnt956K4DG47ijLXBhu+yyywDE\nd3Fzzpw5JvZnrrPZp9nbtm2L+X65pk2bNiYeOnRok+ftpeaCXnatudm7d6+J7e+W3VVVXl6e0j7s\ni+YzZsxI6b2CwCN0IiJHsEEnInKE2CuHZ1ooFNJIIw/sW3iDZJ9OTZkyJeI2/mIO1dXVgeSUiEg/\nu2x9lrku2u9B0J+nP90BAKxcudLE9fXhmTVGjx5typrztAXN5fO01/8tKysD0HgaBX9EFADMnj3b\nxH6emzdvNmVBLlQRQbWqhmJtxCN0IiJHsEEnInJE3o1ysW+nnjBhQhYzIWrKvnGqX79+WczEDfaa\nv3bsKh6hExE5gg06EZEj8q7LpX///iZu165dxG3smRWPHj2a8ZyIiNKBR+hERI7IuyP0aDZu3Gji\nG264wcRcWZ2IcgWP0ImIHMEGnYjIEXl963+u463/6dNcblV3BT/PtOOt/0RE+YQNOhGRIwLtchGR\ngwB+BHAosJ0GryNYv1zG+uUul+t2sarGXCw10AYdAESkKp6+oFzF+uU21i93uVy3eLHLhYjIEWzQ\niYgckY0GfXbsTXIa65fbWL/c5XLd4hJ4HzoREWUGu1yIiBwRaIMuIoNFpEZEdorI5CD3nQki0lVE\nlovIFhHZLCLlXnkHEVkmIju8/9tnO9dkiUiBiKwXkcXeY5fqdq6IzBeRbSKyVUT+07H6/cH7Xn4p\nIvNE5Oxcrp+IzBGRehH50iqLWh8RmeK1NTUi8l/ZyTpYgTXoIlIAYAaAIQB6ABgtIj2C2n+GnATw\nR1XtAaAvgPFenSYDqFTVUgCV3uNcVQ5gq/XYpbr9L4CPVfU/AFyJcD2dqJ+IdAHwMICQqvYEUADg\nLuR2/f4KYPBpZRHr4/0e3gXgMu81r3htkNOCPELvA2Cnqu5W1eMA3gIwIsD9p52q1qrqF158BOEG\noQvC9ZrrbTYXwC3ZyTA1InIRgJsA/MUqdqVu5wC4HsBrAKCqx1X1ezhSP08LAG1EpAWAtgC+Rg7X\nT1VXAvjXacXR6jMCwFuq+ouq/hPAToTbIKcF2aB3AbDPerzfK3OCiBQD6AVgLYDOqlrrPVUHoHOW\n0krV/wB4FMCvVpkrdSsBcBDA/3ldSn8Rkd/Akfqp6gEALwLYC6AWwA+q+gkcqZ8lWn2cbm+i4UXR\nNBCRdgAWAPi9qh62n9PwMKKcG0okIsMA1KtqdbRtcrVunhYArgYwU1V7ITwlRaPuh1yun9eXPALh\nP1wXAviNiIyxt8nl+kXiWn2SEWSDfgBAV+vxRV5ZThORlgg35n9T1YVe8TciUug9XwigPlv5peC3\nAG4Wka8Q7h67QUTehBt1A8JHbPtVda33eD7CDbwr9RsE4J+qelBVTwBYCKAf3KmfL1p9nGxvYgmy\nQV8HoFRESkSkFcIXLCoC3H/aSXhy59cAbFXV6dZTFQDGevFYAIuCzi1VqjpFVS9S1WKEf1afquoY\nOFA3AFDVOgD7RKS7VzQQwBY4Uj+Eu1r6ikhb73s6EOFrPK7UzxetPhUA7hKR1iJSAqAUwN+zkF+w\nVDWwfwCGAtgOYBeAqUHuO0P1uQ7hU7x/ANjg/RsK4DyEr7jvAPD/ADpkO9cU6zkAwGIvdqZuAK4C\nUOX9/N4H0N6x+v0JwDYAXwJ4A0DrXK4fgHkIXw84gfAZ1n1nqg+AqV5bUwNgSLbzD+If7xQlInIE\nL4oSETmCDToRkSPYoBMROYINOhGRI9igExE5gg06EZEj2KATETmCDToRkSP+DSCAE4T7/X2TAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdd286cc890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s'%classes[labels[j]] for j in range(4)))\n",
    "\n",
    "outputs = net(Variable(images))\n",
    "#outputs = net(Variable(images).cuda())  #cuda\n",
    "\n",
    "# the outputs are energies for the 10 classes.\n",
    "# Higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class\n",
    "\n",
    "# So, let's get the index of the highest energy\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "p = torch.max(outputs.data, 1)\n",
    "print predicted,p\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s'% classes[predicted[j][0]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data    \n",
    "    #images, labels = Variable(images.cuda()), Variable(labels.cuda()) #cuda\n",
    "    #images, labels = Variable(images), Variable(labels) \n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    #correct += (predicted == labels.data).sum()  #cuda\n",
    "    \n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of     0 : 97 %\n",
      "Accuracy of     1 : 98 %\n",
      "Accuracy of     2 : 95 %\n",
      "Accuracy of     3 : 97 %\n",
      "Accuracy of     4 : 96 %\n",
      "Accuracy of     5 : 94 %\n",
      "Accuracy of     6 : 94 %\n",
      "Accuracy of     7 : 94 %\n",
      "Accuracy of     8 : 93 %\n",
      "Accuracy of     9 : 92 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))classes = ('0','1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    #images, labels = Variable(images.cuda()), Variable(labels.cuda()) #cuda \n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    #c = (predicted == labels.data).squeeze()  #cuda\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        #label = labels[i].data #cuda\n",
    "        #label = label.cpu().numpy()[0]  #cuda\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'/home/wang/git/cifar10/mnist.weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
